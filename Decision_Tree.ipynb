{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seperating by outcme: Done\n",
      "starting clustering by month:\n",
      "done\n",
      "started droping unnecessary rows:\n",
      "done\n",
      "started droping unnecessary columns:\n",
      "\n",
      " fitting 1 time without cross validation:\n",
      "\n",
      "(array([0.95076401, 0.62843296]), array([0.87958115, 0.81722689]), array([0.91378841, 0.71050228]), array([1910,  476]))\n",
      "\n",
      "For Decision Tree ,\n",
      "\n",
      "\t After cross validation the  different scores are as follows:\n",
      "recall: [0.84051724 0.83189655 0.84913793 0.82758621 0.80818966 0.79525862\n",
      " 0.84051724 0.83405172 0.80603448 0.79310345] \n",
      "\n",
      " precision: [0.62600321 0.6369637  0.65448505 0.63681592 0.64102564 0.62755102\n",
      " 0.6200318  0.63338789 0.61011419 0.58598726] \n",
      "\n",
      " accuracy: [0.87133277 0.87510478 0.88348701 0.87468567 0.87463312 0.86834382\n",
      " 0.8687631  0.87379455 0.86205451 0.85073375] \n",
      "\n",
      " fscore: [0.7175713  0.72149533 0.73921201 0.71977507 0.71496663 0.70152091\n",
      " 0.7136322  0.72       0.69452182 0.67399267] \n",
      "\n",
      "\n",
      "recall mean   : 0.82 with starderd deviation: 0.019\n",
      "precision mean: 0.63 with starderd deviation: 0.019\n",
      "accuracy mean : 0.87 with starderd deviation: 0.019\n",
      "fscore   mean : 0.71 with starderd deviation: 0.019\n",
      "Time taken: 196.98739361763\n"
     ]
    }
   ],
   "source": [
    "##importing necessary libraries\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "import sklearn.tree\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## RETURNS percentage% OF DATAFrame AFTER SAMPLING\n",
    "\n",
    "def sampling(dataframe,percentage):\n",
    "    \n",
    "    return dataframe.sample(frac=percentage).reset_index(drop=True)\n",
    "    \n",
    "\n",
    "## PRE-PROCESSING:\n",
    "## CONVERTS WORD CLASSES TO NUMERIC CLASSES:\n",
    "def preprocess_word_to_num(dataframe):\n",
    "    df_copy=dataframe.copy(deep=True)\n",
    "       \n",
    "    for column in df_copy.columns:\n",
    "        if column==\"y\":\n",
    "            df_copy[column]=df_copy[column].replace({\"yes\":1,\"no\":0}) \n",
    "        if column==\"job\":\n",
    "            df_copy[\"job\"].replace({\"management\":1,\n",
    "                                    \"blue-collar\":2,\n",
    "                                    \"admin\":3,\n",
    "                                    \"entrepreneur\":4,\n",
    "                                    \"services\":5,\n",
    "                                    \"self-employed\":6,\n",
    "                                    \"retired\":7,\n",
    "                                    \"technician\":8,\n",
    "                                    \"housemaid\":9,\n",
    "                                    \"student\":10,\n",
    "                                    \"unemployed\":11,\n",
    "                                    \"unknown\":12})\n",
    "        value=df_copy[column][df_copy.first_valid_index()]\n",
    "   \n",
    "        if not (isinstance(value, np.int64) or isinstance(value, np.float64)):\n",
    "            l1=list(set(df_copy[column]))\n",
    "            l2=list(range(0,len(list(set(df_copy[column])))))\n",
    "            df_copy[column]=df_copy[column].replace(l1,l2)\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "##NORMALIZES THE FEATURE DATA POINTS BY REPLACING X WITH (X-X_MEAN)/X_STD\n",
    "\n",
    "def normalize(dataframe):\n",
    "        df_copy=dataframe.copy(deep=True)\n",
    "        for column in df_copy.columns:\n",
    "            std_dev=np.std(df_copy[column])\n",
    "            mean=np.mean(df_copy[column])\n",
    "            l1=list(set(df_copy[column]))\n",
    "            l2=list((item-mean)/std_dev for item in l1)\n",
    "            df_copy[column]=df_copy[column].replace(l1,l2)\n",
    "        return df_copy\n",
    "\n",
    "    \n",
    "##DROPS UNNECESSARY FEARURE FFROM TRAINING DATA:\n",
    "\n",
    "def drop_column(dataframe,col):\n",
    "    return dataframe.drop(col,axis=1)\n",
    "\n",
    "\n",
    "#counting time from now\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "#redaing data from csv\n",
    "\n",
    "url=\"https://github.com/shadow23-cmi/DT-SVM-NB/raw/master/bank-additional-full.csv\"\n",
    "df1=pd.read_csv(url,sep=\";\")\n",
    "\n",
    "#storing all the distinct months and distinct consumer price index\n",
    "# as, dividing the data points on maothly basis needs these 2 parameters\n",
    "#  as, there are more than 1 year and no 2 same month of diff year have same same consumer price index\n",
    "\n",
    "month_unique=list(set(df1[\"month\"]))\n",
    "cons_price_idx_unique=list(set(df1[\"cons.price.idx\"]))\n",
    "\n",
    "\n",
    "\n",
    "#seperating on basis of outcome\n",
    "#so that the majority class can be undersampled for better fitting\n",
    "\n",
    "df_no=df1[df1[\"y\"]==\"no\"]\n",
    "df_yes=df1[df1[\"y\"]==\"yes\"]\n",
    "\n",
    "print(\"Seperating by outcme: Done\")\n",
    "\n",
    "\n",
    "#reseting df_no indices\n",
    "\n",
    "df_no=df_no.reset_index(drop=True)\n",
    "\n",
    "#taking only the following features while calculating data point distances\n",
    "# as, taking monthly data for clustering the rest of the features are of no need as they are monthly data\n",
    "#  so, no difference is made\n",
    "\n",
    "df_no_undersampling_clustered=df_no[[\"age\", 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
    "                                    'contact', 'day_of_week', \"month\", 'campaign', 'pdays',\"cons.price.idx\"]]\n",
    "\n",
    "print(\"starting clustering by month:\")\n",
    "\n",
    "\n",
    "#this object will give distance matrix based on \"taxi cab \" matrix:\n",
    "\n",
    "dist = DistanceMetric.get_metric('manhattan')\n",
    "\n",
    "# contains the ps than can be deleted for under-sampling\n",
    "# and their centers\n",
    "\n",
    "pts_to_delete=[]\n",
    "centers=[]\n",
    "\n",
    "# Here we are calculating the distance matrix of monthly data pts\n",
    "#  since, the distance matrix is symmetric we are considering only the upper triangular part\n",
    "#   there, the pts that  have >= 4 pts in therir 2 radius neighbourhood are only selected \n",
    "#    and, the rst of the pts in its neighbourhood are discarded\n",
    "for month in month_unique:\n",
    "    for index in cons_price_idx_unique:\n",
    "        \n",
    "        \n",
    "        df_month_wise=df_no_undersampling_clustered.loc[(df_no_undersampling_clustered[\"month\"] == month )\n",
    "                                                        &(df_no_undersampling_clustered[\"cons.price.idx\"]==index)]\n",
    "        start_index=df_month_wise.first_valid_index()\n",
    "               \n",
    "        if not df_month_wise.empty:\n",
    "            \n",
    "            df_month_wise=preprocess_word_to_num(df_month_wise)\n",
    "            distance_matrix=dist.pairwise(df_month_wise)\n",
    "            \n",
    "            for i in range(len(distance_matrix)):\n",
    "                \n",
    "                temp=[]\n",
    "                \n",
    "                for j in range(i+1,len(distance_matrix)):\n",
    "                    \n",
    "                    if distance_matrix[i][j]==0:\n",
    "                        pts_to_delete.append(j+start_index)\n",
    "                    \n",
    "                    if distance_matrix[i][j]<=2:\n",
    "                        temp.append(j+start_index)        \n",
    "                \n",
    "                if len(temp)>=4:\n",
    "                    pts_to_delete += temp\n",
    "                    centers.append(i+start_index)\n",
    "\n",
    "\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "\n",
    "#storing unnecessary data pts\n",
    "\n",
    "drop=list((set(pts_to_delete)))\n",
    "\n",
    "\n",
    "print(\"started droping unnecessary rows:\")\n",
    "\n",
    "#Dropping the unnecesary data pts after clustering\n",
    "\n",
    "df_no.drop(df_no.index[drop],inplace=True)\n",
    "print(\"done\")\n",
    "df_no=df_no.reset_index(drop=True)\n",
    "\n",
    "#taking 80% the no clss data\n",
    "\n",
    "df_no=sampling(df_no,0.8)\n",
    "\n",
    "#creating mixed data types by combining all yes class and no clss data\n",
    "#randomsampling them\n",
    "\n",
    "df=df_no.append(df_yes)\n",
    "df=df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "#Pre processing data by sampling and converting str data types to numerical types:\n",
    "\n",
    "df=sampling(df,1)\n",
    "df=preprocess_word_to_num(df)\n",
    "\n",
    "print(\"started droping unnecessary columns:\")\n",
    "\n",
    "#Dropping unnecessary features\n",
    "\n",
    "df2=drop_column(df,\"y\")\n",
    "df2=drop_column(df2,\"campaign\")\n",
    "df2=drop_column(df2,\"month\")\n",
    "df2=drop_column(df2,\"contact\")\n",
    "df2=drop_column(df2,\"education\")\n",
    "\n",
    "\n",
    "#Normalizing the features to mean 0 standerd deviation 1\n",
    "\n",
    "df2=normalize(df2)\n",
    "\n",
    "\n",
    "# Final Data for fitting:\n",
    "\n",
    "data=df2.to_numpy()\n",
    "target=df[\"y\"].to_numpy()\n",
    "\n",
    "\n",
    "#Fitting Decision Tree model:\n",
    "\n",
    "print(\"\\n fitting 1 time without cross validation:\\n\")\n",
    "decision_tree=sklearn.tree.DecisionTreeClassifier(criterion=\"gini\",\n",
    "                                          max_depth=7,\n",
    "                                          min_samples_leaf=50,\n",
    "                                          class_weight={1:2,0:1})  #yes:2 is giving the best result so far\n",
    "\n",
    "data_train,data_test,target_train,target_test=train_test_split(data,\n",
    "                                                               target,\n",
    "                                                               test_size=.1,\n",
    "                                                               shuffle=True)\n",
    "decision_tree.fit(data_train,target_train)\n",
    "\n",
    "target_pred=decision_tree.predict(data_test)\n",
    "p_r_f=precision_recall_fscore_support(target_test,target_pred)\n",
    "print(p_r_f)\n",
    "\n",
    "#CROSS-VALIDATION\n",
    "\n",
    "crs=cross_validate(decision_tree,\n",
    "                   data,\n",
    "                   target,\n",
    "                   cv=10,\n",
    "                   scoring=[\"recall\",\"precision\",\"accuracy\",\"f1\"],\n",
    "                   n_jobs=2)\n",
    "\n",
    "#printing output:\n",
    "\n",
    "print(\"\\nFor Decision Tree ,\\n\")\n",
    "print(\"\\t After cross validation the  different scores are as follows:\")\n",
    "print(\"recall:\",crs[\"test_recall\"],\"\\n\\n\",\n",
    "      \"precision:\",crs[\"test_precision\"],\"\\n\\n\",\n",
    "      \"accuracy:\",crs[\"test_accuracy\"],\"\\n\\n\",\n",
    "      \"fscore:\",crs[\"test_f1\"],\"\\n\\n\")\n",
    "print(\"recall mean   :\", round(crs[\"test_recall\"].mean(),2),\"with starderd deviation:\",round(crs[\"test_recall\"].std(),3))\n",
    "print(\"precision mean:\",round(crs[\"test_precision\"].mean(),2),\"with starderd deviation:\",round(crs[\"test_recall\"].std(),3))\n",
    "print(\"accuracy mean :\",round(crs[\"test_accuracy\"].mean(),2),\"with starderd deviation:\",round(crs[\"test_recall\"].std(),3))\n",
    "print(\"fscore   mean :\",round(crs[\"test_f1\"].mean(),2),\"with starderd deviation:\",round(crs[\"test_recall\"].std(),3))\n",
    "\n",
    "end=time.time()\n",
    "total_time=end-start\n",
    "#outputfile:\n",
    "\n",
    "output_file=open(\"output_file.txt\",\"a+\")\n",
    "\n",
    "output_file.write(\"\\nFor Decision Tree ,\\n\")\n",
    "output_file.write(\"\\t After cross validation the  different scores are as follows:\")\n",
    "\n",
    "output_file.write(\"\\n\\n\\t accuracy: \\t\")\n",
    "output_file.write(str(crs[\"test_accuracy\"]))\n",
    "\n",
    "output_file.write(\"\\n\\n\\t recall: \\t\")\n",
    "\n",
    "output_file.write(str(crs[\"test_recall\"])) \n",
    "output_file.write(\"\\n\\n\\t precision: \\t\")\n",
    "\n",
    "\n",
    "output_file.write(str(crs[\"test_precision\"])) \n",
    "output_file.write(\"\\n\\n\\t fscore: \\t\")\n",
    "\n",
    "output_file.write(str(str(crs[\"test_f1\"])))                  \n",
    "\n",
    "x=\"\\n\\t recall mean   :\\t\"+str(round(crs[\"test_recall\"].mean(),2))+\"\\t with starderd deviation:\\t\"+str(round(crs[\"test_recall\"].std(),3))\n",
    "output_file.write(x)\n",
    "y=\"\\n\\t precision mean:\\t\"+str(round(crs[\"test_precision\"].mean(),2))+\"\\t with starderd deviation:\\t\"+str(round(crs[\"test_recall\"].std(),3))\n",
    "output_file.write(y)\n",
    "z=\"\\n\\t accuracy mean :\\t\"+str(round(crs[\"test_accuracy\"].mean(),2))+\"\\t with starderd deviation:\\t\"+str(round(crs[\"test_recall\"].std(),3))\n",
    "output_file.write(z)\n",
    "f1=\"\\n\\t fscore mean   :\\t\"+str(round(crs[\"test_f1\"].mean(),2))+\"\\t with starderd deviation:\\t\"+str(round(crs[\"test_f1\"].std(),3))\n",
    "output_file.write(f1)\n",
    "output_file.write(\"\\n\")\n",
    "output_file.write(\"Time taken: \"+str(total_time)+\"secs\")\n",
    "output_file.write(\"\\n ===================================================================\")\n",
    "output_file.close()\n",
    "\n",
    "print(\"Time taken:\",end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
